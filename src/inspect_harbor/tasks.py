"""Harbor registry dataset tasks.

This file is auto-generated by scripts/generate_tasks.py.
Do not edit manually.

Registry: https://raw.githubusercontent.com/laude-institute/harbor/refs/heads/main/registry.json
"""

from inspect_ai import Task, task

from inspect_harbor.harbor._task import harbor as _harbor_base


@task
def aider_polyglot_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""A polyglot coding benchmark that evaluates AI agents' ability to perform code editing and generation tasks across multiple programming languages.

    Dataset: aider-polyglot@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="aider-polyglot@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def aider_polyglot(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""A polyglot coding benchmark that evaluates AI agents' ability to perform code editing and generation tasks across multiple programming languages.

    Dataset: aider-polyglot
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="aider-polyglot",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def aime_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""American Invitational Mathematics Examination (AIME) benchmark for evaluating mathematical reasoning and problem-solving capabilities. Contains 60 competition-level mathematics problems from AIME 2024, 2025-I, and 2025-II competitions.

    Dataset: aime@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="aime@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def aime(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""American Invitational Mathematics Examination (AIME) benchmark for evaluating mathematical reasoning and problem-solving capabilities. Contains 60 competition-level mathematics problems from AIME 2024, 2025-I, and 2025-II competitions.

    Dataset: aime
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="aime",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def algotune_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""AlgoTune: 154 algorithm optimization tasks focusing on speedup-based scoring from the AlgoTune benchmark.

    Dataset: algotune@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="algotune@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def algotune(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""AlgoTune: 154 algorithm optimization tasks focusing on speedup-based scoring from the AlgoTune benchmark.

    Dataset: algotune
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="algotune",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def arc_agi_2_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""ARC-AGI-2: A benchmark measuring abstract reasoning through visual grid puzzles requiring rule inference and generalization.

    Dataset: arc_agi_2@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="arc_agi_2@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def arc_agi_2(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""ARC-AGI-2: A benchmark measuring abstract reasoning through visual grid puzzles requiring rule inference and generalization.

    Dataset: arc_agi_2
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="arc_agi_2",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def autocodebench_lite200(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""Adapter for AutoCodeBench (https://github.com/Tencent-Hunyuan/AutoCodeBenchmark).

    Dataset: autocodebench@lite200
    Version: lite200
    """
    return _harbor_base(
        dataset_name_version="autocodebench@lite200",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def autocodebench(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""Adapter for AutoCodeBench (https://github.com/Tencent-Hunyuan/AutoCodeBenchmark).

    Dataset: autocodebench
    Version: Latest available (lite200 when generated)
    """
    return _harbor_base(
        dataset_name_version="autocodebench",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def bixbench_1_5(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""BixBench - A benchmark for evaluating AI agents on bioinformatics and computational biology tasks.

    Dataset: bixbench@1.5
    Version: 1.5
    """
    return _harbor_base(
        dataset_name_version="bixbench@1.5",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def bixbench(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""BixBench - A benchmark for evaluating AI agents on bioinformatics and computational biology tasks.

    Dataset: bixbench
    Version: Latest available (1.5 when generated)
    """
    return _harbor_base(
        dataset_name_version="bixbench",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def bixbench_cli_1_5(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""bixbench-cli - A benchmark for evaluating AI agents on bioinformatics and computational biology tasks. (Adapted for CLI execution)

    Dataset: bixbench-cli@1.5
    Version: 1.5
    """
    return _harbor_base(
        dataset_name_version="bixbench-cli@1.5",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def bixbench_cli(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""bixbench-cli - A benchmark for evaluating AI agents on bioinformatics and computational biology tasks. (Adapted for CLI execution)

    Dataset: bixbench-cli
    Version: Latest available (1.5 when generated)
    """
    return _harbor_base(
        dataset_name_version="bixbench-cli",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def codepde_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""CodePDE evaluates code generation capabilities on scientific computing tasks, specifically focusing on Partial Differential Equation (PDE) solving.

    Dataset: codepde@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="codepde@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def codepde(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""CodePDE evaluates code generation capabilities on scientific computing tasks, specifically focusing on Partial Differential Equation (PDE) solving.

    Dataset: codepde
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="codepde",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def compilebench_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""Version 1.0 of CompileBench, a benchmark on real open-source projects against dependency hell, legacy toolchains, and complex build systems.

    Dataset: compilebench@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="compilebench@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def compilebench(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""Version 1.0 of CompileBench, a benchmark on real open-source projects against dependency hell, legacy toolchains, and complex build systems.

    Dataset: compilebench
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="compilebench",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def crustbench_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""CRUST-bench: 100 C-to-safe-Rust transpilation tasks from real-world C repositories.

    Dataset: crustbench@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="crustbench@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def crustbench(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""CRUST-bench: 100 C-to-safe-Rust transpilation tasks from real-world C repositories.

    Dataset: crustbench
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="crustbench",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def ds_1000_head(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""DS-1000 is a code generation benchmark with 1000 realistic data science problems across seven popular Python libraries.

    Dataset: ds-1000@head
    Version: head
    """
    return _harbor_base(
        dataset_name_version="ds-1000@head",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def ds_1000(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""DS-1000 is a code generation benchmark with 1000 realistic data science problems across seven popular Python libraries.

    Dataset: ds-1000
    Version: Latest available (head when generated)
    """
    return _harbor_base(
        dataset_name_version="ds-1000",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def evoeval_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""EvoEval_difficult: 100 challenging Python programming tasks evolved from HumanEval.

    Dataset: evoeval@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="evoeval@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def evoeval(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""EvoEval_difficult: 100 challenging Python programming tasks evolved from HumanEval.

    Dataset: evoeval
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="evoeval",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def gpqa_diamond_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""GPQA Diamond subset: 198 graduate-level multiple-choice questions in biology, physics, and chemistry for evaluating scientific reasoning.

    Dataset: gpqa-diamond@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="gpqa-diamond@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def gpqa_diamond(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""GPQA Diamond subset: 198 graduate-level multiple-choice questions in biology, physics, and chemistry for evaluating scientific reasoning.

    Dataset: gpqa-diamond
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="gpqa-diamond",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def hello_world_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""A simple example task to create a hello.txt file with 'Hello, world!' as content.

    Dataset: hello-world@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="hello-world@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def hello_world(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""A simple example task to create a hello.txt file with 'Hello, world!' as content.

    Dataset: hello-world
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="hello-world",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def humanevalfix_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""HumanEvalFix: 164 Python code repair tasks from HumanEvalPack.

    Dataset: humanevalfix@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="humanevalfix@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def humanevalfix(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""HumanEvalFix: 164 Python code repair tasks from HumanEvalPack.

    Dataset: humanevalfix
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="humanevalfix",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def ineqmath_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""This adapter brings IneqMath, the dev set of the first inequality-proof Q\&A benchmark for LLMs, into Harbor, enabling standardized evaluation of models on mathematical reasoning and proof construction.

    Dataset: ineqmath@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="ineqmath@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def ineqmath(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""This adapter brings IneqMath, the dev set of the first inequality-proof Q\&A benchmark for LLMs, into Harbor, enabling standardized evaluation of models on mathematical reasoning and proof construction.

    Dataset: ineqmath
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="ineqmath",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def lawbench_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""LawBench: Benchmarking Legal Knowledge of Large Language Models

    Dataset: lawbench@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="lawbench@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def lawbench(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""LawBench: Benchmarking Legal Knowledge of Large Language Models

    Dataset: lawbench
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="lawbench",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def livecodebench_6_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""A subset of 100 sampled tasks from the release_v6 version of LiveCodeBench tasks.

    Dataset: livecodebench@6.0
    Version: 6.0
    """
    return _harbor_base(
        dataset_name_version="livecodebench@6.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def livecodebench(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""A subset of 100 sampled tasks from the release_v6 version of LiveCodeBench tasks.

    Dataset: livecodebench
    Version: Latest available (6.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="livecodebench",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def mlgym_bench_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""Evaluates agents on ML tasks across computer vision, RL, tabular ML, and game theory.

    Dataset: mlgym-bench@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="mlgym-bench@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def mlgym_bench(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""Evaluates agents on ML tasks across computer vision, RL, tabular ML, and game theory.

    Dataset: mlgym-bench
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="mlgym-bench",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def mmau_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""MMAU: 1000 carefully curated audio clips paired with human-annotated natural language questions and answers spanning speech, environmental sounds, and music.

    Dataset: mmau@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="mmau@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def mmau(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""MMAU: 1000 carefully curated audio clips paired with human-annotated natural language questions and answers spanning speech, environmental sounds, and music.

    Dataset: mmau
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="mmau",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def mmmlu_parity(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""MMMLU (Multilingual MMLU) parity validation subset with 10 tasks per language across 15 languages (150 tasks total). Evaluates language models' subject knowledge and reasoning across multiple languages using multiple-choice questions covering 57 academic subjects.

    Dataset: mmmlu@parity
    Version: parity
    """
    return _harbor_base(
        dataset_name_version="mmmlu@parity",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def mmmlu(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""MMMLU (Multilingual MMLU) parity validation subset with 10 tasks per language across 15 languages (150 tasks total). Evaluates language models' subject knowledge and reasoning across multiple languages using multiple-choice questions covering 57 academic subjects.

    Dataset: mmmlu
    Version: Latest available (parity when generated)
    """
    return _harbor_base(
        dataset_name_version="mmmlu",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def reasoning_gym_easy_parity(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""Reasoning Gym benchmark (easy difficulty). Original benchmark: https://github.com/open-thought/reasoning-gym

    Dataset: reasoning-gym-easy@parity
    Version: parity
    """
    return _harbor_base(
        dataset_name_version="reasoning-gym-easy@parity",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def reasoning_gym_easy(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""Reasoning Gym benchmark (easy difficulty). Original benchmark: https://github.com/open-thought/reasoning-gym

    Dataset: reasoning-gym-easy
    Version: Latest available (parity when generated)
    """
    return _harbor_base(
        dataset_name_version="reasoning-gym-easy",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def reasoning_gym_hard_parity(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""Reasoning Gym benchmark (hard difficulty). Original benchmark: https://github.com/open-thought/reasoning-gym

    Dataset: reasoning-gym-hard@parity
    Version: parity
    """
    return _harbor_base(
        dataset_name_version="reasoning-gym-hard@parity",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def reasoning_gym_hard(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""Reasoning Gym benchmark (hard difficulty). Original benchmark: https://github.com/open-thought/reasoning-gym

    Dataset: reasoning-gym-hard
    Version: Latest available (parity when generated)
    """
    return _harbor_base(
        dataset_name_version="reasoning-gym-hard",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def replicationbench_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""ReplicationBench - A benchmark for evaluating AI agents on reproducing computational results from astrophysics research papers. Adapted from Christine8888/replicationbench-release.

    Dataset: replicationbench@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="replicationbench@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def replicationbench(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""ReplicationBench - A benchmark for evaluating AI agents on reproducing computational results from astrophysics research papers. Adapted from Christine8888/replicationbench-release.

    Dataset: replicationbench
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="replicationbench",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def seta_env_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""CAMEL SETA Environment for RL training

    Dataset: seta-env@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="seta-env@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def seta_env(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""CAMEL SETA Environment for RL training

    Dataset: seta-env
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="seta-env",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def sldbench_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""SLDBench: A benchmark for scaling law discovery with symbolic regression tasks.

    Dataset: sldbench@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="sldbench@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def sldbench(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""SLDBench: A benchmark for scaling law discovery with symbolic regression tasks.

    Dataset: sldbench
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="sldbench",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def spider2_dbt_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""Spider 2.0-DBT is a comprehensive code generation agent task that includes 68 examples. Solving these tasks requires models to understand project code, navigating complex SQL environments and handling long contexts, surpassing traditional text-to-SQL challenges.

    Dataset: spider2-dbt@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="spider2-dbt@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def spider2_dbt(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""Spider 2.0-DBT is a comprehensive code generation agent task that includes 68 examples. Solving these tasks requires models to understand project code, navigating complex SQL environments and handling long contexts, surpassing traditional text-to-SQL challenges.

    Dataset: spider2-dbt
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="spider2-dbt",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def strongreject_parity(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""StrongReject benchmark for evaluating LLM safety and jailbreak resistance. Parity subset with 150 tasks (50 prompts * 3 jailbreaks).

    Dataset: strongreject@parity
    Version: parity
    """
    return _harbor_base(
        dataset_name_version="strongreject@parity",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def strongreject(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""StrongReject benchmark for evaluating LLM safety and jailbreak resistance. Parity subset with 150 tasks (50 prompts * 3 jailbreaks).

    Dataset: strongreject
    Version: Latest available (parity when generated)
    """
    return _harbor_base(
        dataset_name_version="strongreject",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def swe_gen_js_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""SWE-gen-JS: 1000 JavaScript/TypeScript bug fix tasks from 30 open-source GitHub repos, generated using SWE-gen.

    Dataset: swe-gen-js@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="swe-gen-js@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def swe_gen_js(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""SWE-gen-JS: 1000 JavaScript/TypeScript bug fix tasks from 30 open-source GitHub repos, generated using SWE-gen.

    Dataset: swe-gen-js
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="swe-gen-js",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def swe_lancer_diamond_all(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""Adapter for SWE-Lancer (https://github.com/openai/preparedness/blob/main/project/swelancer/README.md). Both manager and individual contributor tasks.

    Dataset: swe-lancer-diamond@all
    Version: all
    """
    return _harbor_base(
        dataset_name_version="swe-lancer-diamond@all",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def swe_lancer_diamond(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""Adapter for SWE-Lancer (https://github.com/openai/preparedness/blob/main/project/swelancer/README.md). Both manager and individual contributor tasks.

    Dataset: swe-lancer-diamond
    Version: Latest available (all when generated)
    """
    return _harbor_base(
        dataset_name_version="swe-lancer-diamond",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def swe_lancer_diamond_ic(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""Adapter for SWE-Lancer (https://github.com/openai/preparedness/blob/main/project/swelancer/README.md). Only the individual contributor SWE tasks.

    Dataset: swe-lancer-diamond@ic
    Version: ic
    """
    return _harbor_base(
        dataset_name_version="swe-lancer-diamond@ic",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def swe_lancer_diamond_manager(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""Adapter for SWE-Lancer (https://github.com/openai/preparedness/blob/main/project/swelancer/README.md). Only the manager tasks.

    Dataset: swe-lancer-diamond@manager
    Version: manager
    """
    return _harbor_base(
        dataset_name_version="swe-lancer-diamond@manager",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def swebench_verified_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""A human-validated subset of 500 SWE-bench tasks

    Dataset: swebench-verified@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="swebench-verified@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def swebench_verified(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""A human-validated subset of 500 SWE-bench tasks

    Dataset: swebench-verified
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="swebench-verified",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def swebenchpro_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""SWE-bench Pro: A multi-language software engineering benchmark with 731 instances covering Python, JavaScript/TypeScript, and Go. Evaluates AI systems' ability to resolve real-world bugs and implement features across diverse production codebases. Original benchmark: https://github.com/scaleapi/SWE-bench_Pro-os. Adapter details: https://github.com/laude-institute/harbor/tree/main/adapters/swebenchpro

    Dataset: swebenchpro@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="swebenchpro@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def swebenchpro(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""SWE-bench Pro: A multi-language software engineering benchmark with 731 instances covering Python, JavaScript/TypeScript, and Go. Evaluates AI systems' ability to resolve real-world bugs and implement features across diverse production codebases. Original benchmark: https://github.com/scaleapi/SWE-bench_Pro-os. Adapter details: https://github.com/laude-institute/harbor/tree/main/adapters/swebenchpro

    Dataset: swebenchpro
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="swebenchpro",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def swesmith_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""SWE-smith is a synthetically generated dataset of software engineering tasks derived from GitHub issues for training and evaluating code generation models.

    Dataset: swesmith@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="swesmith@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def swesmith(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""SWE-smith is a synthetically generated dataset of software engineering tasks derived from GitHub issues for training and evaluating code generation models.

    Dataset: swesmith
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="swesmith",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def swtbench_verified_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""SWTBench Verified - Software Testing Benchmark for code generation

    Dataset: swtbench-verified@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="swtbench-verified@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def swtbench_verified(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""SWTBench Verified - Software Testing Benchmark for code generation

    Dataset: swtbench-verified
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="swtbench-verified",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def terminal_bench_2_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""Version 2.0 of Terminal-Bench, a benchmark for testing agents in terminal environments. More tasks, harder, and higher quality than 1.0.

    Dataset: terminal-bench@2.0
    Version: 2.0
    """
    return _harbor_base(
        dataset_name_version="terminal-bench@2.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def terminal_bench(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""Version 2.0 of Terminal-Bench, a benchmark for testing agents in terminal environments. More tasks, harder, and higher quality than 1.0.

    Dataset: terminal-bench
    Version: Latest available (2.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="terminal-bench",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def terminal_bench_pro_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""Terminal-Bench Pro (Public Set) is an extended benchmark dataset for testing AI agents in real terminal environments. From compiling code to training models and setting up servers, Terminal-Bench Pro evaluates how well agents can handle real-world, end-to-end tasks autonomously.

    Dataset: terminal-bench-pro@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="terminal-bench-pro@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def terminal_bench_pro(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""Terminal-Bench Pro (Public Set) is an extended benchmark dataset for testing AI agents in real terminal environments. From compiling code to training models and setting up servers, Terminal-Bench Pro evaluates how well agents can handle real-world, end-to-end tasks autonomously.

    Dataset: terminal-bench-pro
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="terminal-bench-pro",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def terminal_bench_sample_2_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""A sample of tasks from Terminal-Bench 2.0.

    Dataset: terminal-bench-sample@2.0
    Version: 2.0
    """
    return _harbor_base(
        dataset_name_version="terminal-bench-sample@2.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def terminal_bench_sample(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""A sample of tasks from Terminal-Bench 2.0.

    Dataset: terminal-bench-sample
    Version: Latest available (2.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="terminal-bench-sample",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def usaco_2_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""USACO: 304 Python programming problems from USACO competition.

    Dataset: usaco@2.0
    Version: 2.0
    """
    return _harbor_base(
        dataset_name_version="usaco@2.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def usaco(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""USACO: 304 Python programming problems from USACO competition.

    Dataset: usaco
    Version: Latest available (2.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="usaco",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def vmax_tasks_1_0(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""A collection of 1,043 validated real-world bug-fixing tasks from popular open-source JavaScript projects including Vue.js, Docusaurus, Redux, and Chalk. Each task presents an authentic bug report with reproduction steps and expected behavior.

    Dataset: vmax-tasks@1.0
    Version: 1.0
    """
    return _harbor_base(
        dataset_name_version="vmax-tasks@1.0",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )


@task
def vmax_tasks(
    dataset_task_names: list[str] | None = None,
    dataset_exclude_task_names: list[str] | None = None,
    n_tasks: int | None = None,
    overwrite_cache: bool = False,
    sandbox_env_name: str = "docker",
    override_cpus: int | None = None,
    override_memory_mb: int | None = None,
    override_gpus: int | None = None,
) -> Task:
    r"""A collection of 1,043 validated real-world bug-fixing tasks from popular open-source JavaScript projects including Vue.js, Docusaurus, Redux, and Chalk. Each task presents an authentic bug report with reproduction steps and expected behavior.

    Dataset: vmax-tasks
    Version: Latest available (1.0 when generated)
    """
    return _harbor_base(
        dataset_name_version="vmax-tasks",
        dataset_task_names=dataset_task_names,
        dataset_exclude_task_names=dataset_exclude_task_names,
        n_tasks=n_tasks,
        overwrite_cache=overwrite_cache,
        sandbox_env_name=sandbox_env_name,
        override_cpus=override_cpus,
        override_memory_mb=override_memory_mb,
        override_gpus=override_gpus,
    )
